{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjKiiHjTdGOr"
      },
      "source": [
        "# TP7 ALTEGRAD - LACOMBE Yoach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3tAhIAddGuU",
        "outputId": "5097506b-c737-4c0f-f094-016f0cffb2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n",
            "/gdrive/My Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "%cd 'My Drive'/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y47PuADVt8Np"
      },
      "outputs": [],
      "source": [
        "PATH_DIGINETICA_TEST = './dataset_ALTEGRAD/diginetica_test.p'\n",
        "PATH_DIGINETICA_TRAIN = './dataset_ALTEGRAD/diginetica_train.p'\n",
        "PATH_SOCRATES = './dataset_ALTEGRAD/Socrates_network.xlsx'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hlP3oLPdHFv"
      },
      "source": [
        "## DeepSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6YkYO2Dc_-a"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Learning on Sets - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_train_dataset():\n",
        "    n_train = 100000\n",
        "    max_train_card = 10\n",
        "    X_train = np.zeros((n_train, max_train_card))\n",
        "\n",
        "    ############## Task 1\n",
        "    \n",
        "    ##################\n",
        "    # your code here #\n",
        "    ##################\n",
        "    for j in range(1,11):\n",
        "      X_train[(j-1)*10000:(j)*10000, 0:j] = np.random.randint(1,11, (10000,j))\n",
        "\n",
        "    np.random.shuffle(X_train)\n",
        "    y_train = np.sum(X_train, axis = 1)\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "\n",
        "def create_test_dataset():\n",
        "    \n",
        "    ############## Task 2\n",
        "    \n",
        "    ##################\n",
        "    # your code here #\n",
        "    ##################\n",
        "    n_train = 200000\n",
        "    max_train_card = 100\n",
        "    X_test = []\n",
        "\n",
        "    for j, k in enumerate(range(5,105,5)):\n",
        "      X_test.append(np.random.randint(1,11, (10000,k)))\n",
        "\n",
        "    y_test = [np.sum(x, axis = 1) for x in X_test]\n",
        "\n",
        "    return X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOFPGrpwdYxY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Learning on Sets - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DeepSets(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
        "        super(DeepSets, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ############## Task 3\n",
        "    \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        x = self.embedding(x)\n",
        "        x = self.tanh(self.fc1(x))\n",
        "        x = x.sum(axis = 1)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x.squeeze()\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ############## Task 4\n",
        "    \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        x = self.embedding(x)\n",
        "        x, _  = self.lstm(x)\n",
        "        x = self.fc(x[:,-1,:])\n",
        "        return x.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euwzYaGHddr9",
        "outputId": "d689b489-209a-41eb-a42d-54c33ff3ff25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 0.9113 time: 3.3390s\n",
            "Epoch: 0002 loss_train: 0.0748 time: 3.1972s\n",
            "Epoch: 0003 loss_train: 0.0560 time: 3.3496s\n",
            "Epoch: 0004 loss_train: 0.0513 time: 3.3270s\n",
            "Epoch: 0005 loss_train: 0.0460 time: 3.5921s\n",
            "Epoch: 0006 loss_train: 0.0408 time: 3.4620s\n",
            "Epoch: 0007 loss_train: 0.0372 time: 3.5167s\n",
            "Epoch: 0008 loss_train: 0.0369 time: 3.3907s\n",
            "Epoch: 0009 loss_train: 0.0326 time: 3.3043s\n",
            "Epoch: 0010 loss_train: 0.0326 time: 3.2107s\n",
            "Epoch: 0011 loss_train: 0.0307 time: 3.0868s\n",
            "Epoch: 0012 loss_train: 0.0310 time: 3.3228s\n",
            "Epoch: 0013 loss_train: 0.0293 time: 3.1716s\n",
            "Epoch: 0014 loss_train: 0.0279 time: 3.5067s\n",
            "Epoch: 0015 loss_train: 0.0280 time: 5.7453s\n",
            "Epoch: 0016 loss_train: 0.0264 time: 4.3298s\n",
            "Epoch: 0017 loss_train: 0.0257 time: 3.3516s\n",
            "Epoch: 0018 loss_train: 0.0270 time: 3.2751s\n",
            "Epoch: 0019 loss_train: 0.0270 time: 3.2437s\n",
            "Epoch: 0020 loss_train: 0.0247 time: 3.1513s\n",
            "Finished training for DeepSets model\n",
            "\n",
            "Epoch: 0001 loss_train: 10.2522 time: 15.1019s\n",
            "Epoch: 0002 loss_train: 0.4518 time: 15.3563s\n",
            "Epoch: 0003 loss_train: 0.2300 time: 15.3681s\n",
            "Epoch: 0004 loss_train: 0.1896 time: 15.7405s\n",
            "Epoch: 0005 loss_train: 0.1741 time: 15.8568s\n",
            "Epoch: 0006 loss_train: 0.1626 time: 15.7492s\n",
            "Epoch: 0007 loss_train: 0.1522 time: 18.5234s\n",
            "Epoch: 0008 loss_train: 0.1401 time: 19.4862s\n",
            "Epoch: 0009 loss_train: 0.1367 time: 16.1640s\n",
            "Epoch: 0010 loss_train: 0.1356 time: 18.3055s\n",
            "Epoch: 0011 loss_train: 0.1249 time: 19.1335s\n",
            "Epoch: 0012 loss_train: 0.1256 time: 18.2256s\n",
            "Epoch: 0013 loss_train: 0.1219 time: 16.7246s\n",
            "Epoch: 0014 loss_train: 0.1235 time: 19.7223s\n",
            "Epoch: 0015 loss_train: 0.1117 time: 19.9258s\n",
            "Epoch: 0016 loss_train: 0.1178 time: 25.6299s\n",
            "Epoch: 0017 loss_train: 0.1146 time: 18.5800s\n",
            "Epoch: 0018 loss_train: 0.1117 time: 17.5111s\n",
            "Epoch: 0019 loss_train: 0.1064 time: 28.8966s\n",
            "Epoch: 0020 loss_train: 0.1094 time: 20.4485s\n",
            "Finished training for LSTM model\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Learning on Sets - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "# Initializes device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "embedding_dim = 128\n",
        "hidden_dim = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Generates training data\n",
        "X_train, y_train = create_train_dataset()\n",
        "n_train = 100000\n",
        "n_digits = 11\n",
        "\n",
        "# Initializes DeepSets model and optimizer\n",
        "deepsets = DeepSets(n_digits, embedding_dim, hidden_dim).to(device)\n",
        "optimizer = optim.Adam(deepsets.parameters(), lr=learning_rate)\n",
        "loss_function = nn.L1Loss()\n",
        "\n",
        "# Trains the DeepSets model\n",
        "for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "    deepsets.train()\n",
        "     \n",
        "    train_loss = 0\n",
        "    count = 0\n",
        "    idx = np.random.permutation(n_train)\n",
        "    for i in range(0, n_train, batch_size):\n",
        "        \n",
        "        ############## Task 5\n",
        "    \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        x_batch = X_train[i:batch_size + i,:]\n",
        "        y_batch = y_train[i:batch_size + i]\n",
        "\n",
        "        x_batch = torch.Tensor(x_batch).type(torch.long)\n",
        "        y_batch = torch.Tensor(y_batch).type(torch.long)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = deepsets(x_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * output.size(0)\n",
        "        count += output.size(0)\n",
        "    \n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(train_loss / count),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "# Stores DeepSets model into disk\n",
        "torch.save({\n",
        "    'state_dict': deepsets.state_dict(),\n",
        "    'optimizer' : optimizer.state_dict(),\n",
        "}, 'model_deepsets.pth.tar')\n",
        "\n",
        "print(\"Finished training for DeepSets model\")\n",
        "print()\n",
        "\n",
        "# Initializes LSTM model and optimizer\n",
        "lstm = LSTM(n_digits, embedding_dim, hidden_dim).to(device)\n",
        "optimizer = optim.Adam(lstm.parameters(), lr=learning_rate)\n",
        "loss_function = nn.L1Loss()\n",
        "\n",
        "# Trains the LSTM model\n",
        "for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "    lstm.train()\n",
        "     \n",
        "    train_loss = 0\n",
        "    count = 0\n",
        "    idx = np.random.permutation(n_train)\n",
        "    for i in range(0, n_train, batch_size):\n",
        "    \n",
        "        ############## Task 5\n",
        "        \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        x_batch = X_train[i:batch_size + i,:]\n",
        "        y_batch = y_train[i:batch_size + i]\n",
        "\n",
        "        x_batch = torch.Tensor(x_batch).type(torch.long)\n",
        "        y_batch = torch.Tensor(y_batch).type(torch.long)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = lstm(x_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * output.size(0)\n",
        "        count += output.size(0)\n",
        "    \n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(train_loss / count),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "# Stores LSTM model into disk\n",
        "torch.save({\n",
        "    'state_dict': lstm.state_dict(),\n",
        "    'optimizer' : optimizer.state_dict(),\n",
        "}, 'model_lstm.pth.tar')\n",
        "\n",
        "print(\"Finished training for LSTM model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUnfIaf1djNI",
        "outputId": "bcb0b99e-455a-4132-cc77-4012d8c4b9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading DeepSets checkpoint!\n",
            "Loading LSTM checkpoint!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Learning on Sets - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "import torch\n",
        "\n",
        "\n",
        "# Initializes device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "embedding_dim = 128\n",
        "hidden_dim = 64\n",
        "\n",
        "# Generates test data\n",
        "X_test, y_test = create_test_dataset()\n",
        "cards = [X_test[i].shape[1] for i in range(len(X_test))]\n",
        "n_samples_per_card = X_test[0].shape[0]\n",
        "n_digits = 11\n",
        "\n",
        "# Retrieves DeepSets model\n",
        "deepsets = DeepSets(n_digits, embedding_dim, hidden_dim).to(device)\n",
        "print(\"Loading DeepSets checkpoint!\")\n",
        "checkpoint = torch.load('model_deepsets.pth.tar')\n",
        "deepsets.load_state_dict(checkpoint['state_dict'])\n",
        "deepsets.eval()\n",
        "\n",
        "# Retrieves LSTM model\n",
        "lstm = LSTM(n_digits, embedding_dim, hidden_dim).to(device)\n",
        "print(\"Loading LSTM checkpoint!\")\n",
        "checkpoint = torch.load('model_lstm.pth.tar')\n",
        "lstm.load_state_dict(checkpoint['state_dict'])\n",
        "lstm.eval()\n",
        "\n",
        "# Dict to store the results\n",
        "results = {'deepsets': {'acc':[], 'mae':[]}, 'lstm': {'acc':[], 'mae':[]}}\n",
        "\n",
        "for i in range(len(cards)):\n",
        "    y_pred_deepsets = list()\n",
        "    y_pred_lstm = list()\n",
        "    for j in range(0, n_samples_per_card, batch_size):\n",
        "        \n",
        "        ############## Task 6\n",
        "    \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        x_batch = X_test[i][j:batch_size + j,:]\n",
        "        x_batch = torch.Tensor(x_batch).type(torch.long)\n",
        "\n",
        "        y_pred_deepsets.append(deepsets(x_batch))\n",
        "        y_pred_lstm.append(lstm(x_batch))\n",
        "        \n",
        "    y_pred_deepsets = torch.cat(y_pred_deepsets)\n",
        "    y_pred_deepsets = y_pred_deepsets.detach().cpu().numpy()\n",
        "    \n",
        "    acc_deepsets = accuracy_score(y_test[i], np.round(y_pred_deepsets))\n",
        "    mae_deepsets = mean_absolute_error(y_test[i], y_pred_deepsets)\n",
        "    results['deepsets']['acc'].append(acc_deepsets)\n",
        "    results['deepsets']['mae'].append(mae_deepsets)\n",
        "    \n",
        "    y_pred_lstm = torch.cat(y_pred_lstm)\n",
        "    y_pred_lstm = y_pred_lstm.detach().cpu().numpy()\n",
        "    \n",
        "    acc_lstm = accuracy_score(y_test[i], np.round(y_pred_lstm))\n",
        "    mae_lstm = mean_absolute_error(y_test[i], y_pred_lstm)\n",
        "    results['lstm']['acc'].append(acc_lstm)\n",
        "    results['lstm']['mae'].append(mae_lstm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "ZeBYj0TXm-WL",
        "outputId": "ef0d27e7-d9b7-40cd-cf69-31882f831266"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "############## Task 7\n",
        "    \n",
        "##################\n",
        "# your code here #\n",
        "##################\n",
        "\n",
        "plt.plot(cards,results['lstm']['acc'], label = 'accuracy_lstm')\n",
        "plt.plot(cards,results['deepsets']['acc'], label = 'accuracy_deepsets')\n",
        "plt.xlabel('Max cardinality')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cards,results['lstm']['mae'], label = 'mae_lstm')\n",
        "plt.plot(cards,results['deepsets']['mae'], label = 'mae_deepsets')\n",
        "plt.xlabel('Max cardinality')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAPgp-7Edmcd"
      },
      "source": [
        "## Graph-Based Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibQSAX-FdrbM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Graph-based Recommentations - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import pickle\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from scipy.sparse import lil_matrix, block_diag, diags\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    with open(PATH_DIGINETICA_TRAIN, 'rb') as f:\n",
        "        data_train = pickle.load(f)\n",
        "    sessions_train = data_train[0]\n",
        "    y_train = np.array(data_train[1])\n",
        "\n",
        "    with open(PATH_DIGINETICA_TEST, 'rb') as f:\n",
        "        data_test = pickle.load(f)\n",
        "    sessions_test = data_test[0]\n",
        "    y_test = np.array(data_test[1])\n",
        "\n",
        "    ############## Task 8\n",
        "    \n",
        "    ##################\n",
        "    # your code here #\n",
        "    ##################\n",
        "    print('number of training sessions', len(sessions_train))\n",
        "    print('number of testing sessions', len(sessions_test))\n",
        "    my_set = set()\n",
        "    for l in sessions_train:\n",
        "      my_set.update(l)\n",
        "    print('number of unique items in the trainset', len(my_set))\n",
        "    print('max id', max(my_set), \"min\", min(my_set))\n",
        "    print('len of the longest session', max([len(l) for l in sessions_test]))\n",
        "    max_item_id = max(max(my_set), max(y_train))\n",
        "\n",
        "    return sessions_train, sessions_test, y_train, y_test, max_item_id\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col))).long()\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def generate_batches(sessions, y, batch_size, device, shuffle=False):\n",
        "    N = len(sessions)\n",
        "    if shuffle:\n",
        "        index = np.random.permutation(N)\n",
        "    else:\n",
        "        index = np.array(range(N), dtype=np.int32)\n",
        "\n",
        "    n_batches = ceil(N/batch_size)\n",
        "    \n",
        "    adj_lst = list()\n",
        "    items_lst = list()\n",
        "    last_item_lst = list()\n",
        "    idx_lst = list()\n",
        "    targets_lst = list()\n",
        "    \n",
        "    for i in range(0, N, batch_size):\n",
        "        n_nodes = 0\n",
        "        for j in range(i, min(i+batch_size, N)):\n",
        "            n_nodes += np.unique(sessions[index[j]]).size\n",
        "            \n",
        "        adj = list()\n",
        "        items = np.zeros(n_nodes, dtype=np.int32)\n",
        "        last_item = np.zeros(min(i+batch_size, N)-i, dtype=np.int32)\n",
        "        idx = np.zeros(n_nodes, dtype=np.int32)\n",
        "        targets = np.zeros(min(i+batch_size, N)-i, dtype=np.int32)\n",
        "        \n",
        "        node_count = 0\n",
        "        for j in range(i, min(i+batch_size, N)):\n",
        "            nodes = np.unique(sessions[index[j]])\n",
        "            node_to_idx = {nodes[i]:i for i in range(nodes.size)}\n",
        "            A = lil_matrix((nodes.size, nodes.size))\n",
        "            for k in range(nodes.size):\n",
        "                A[k,k] = 1\n",
        "            for k in range(len(sessions[index[j]])-1):\n",
        "                u = node_to_idx[sessions[index[j]][k]]\n",
        "                v = node_to_idx[sessions[index[j]][k+1]]\n",
        "                A[v,u] += 1\n",
        "                A[u,v] += 1\n",
        "            \n",
        "            adj.append(normalize(A))\n",
        "            items[node_count:node_count+nodes.size] = nodes\n",
        "            last_item[j-i] = node_count+node_to_idx[sessions[index[j]][-1]]\n",
        "            idx[node_count:node_count+nodes.size] = j-i\n",
        "            targets[j-i] = y[index[j]]\n",
        "            \n",
        "            node_count += nodes.size\n",
        "        \n",
        "        adj = block_diag(adj)\n",
        "        \n",
        "        adj_lst.append(sparse_mx_to_torch_sparse_tensor(adj).to(device))\n",
        "        items_lst.append(torch.LongTensor(items).to(device))\n",
        "        last_item_lst.append(torch.LongTensor(last_item).to(device))\n",
        "        idx_lst.append(torch.LongTensor(idx).to(device))\n",
        "        targets_lst.append(torch.LongTensor(targets).to(device))\n",
        "   \n",
        "    return adj_lst, items_lst, last_item_lst, idx_lst, targets_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sIlm_JEdv-i"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Graph-based Recommendations - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MessagePassing(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MessagePassing, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, adj, x):\n",
        "        \n",
        "        ############## Task 9\n",
        "    \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        output = self.fc(x)\n",
        "        output = torch.mm(adj,output)\n",
        "        \n",
        "        return output\n",
        "\n",
        "\n",
        "class SR_GNN(nn.Module):\n",
        "    def __init__(self, n_items, hidden_dim, dropout, device):\n",
        "        super(SR_GNN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "        self.embedding = nn.Embedding(n_items, hidden_dim)\n",
        "        self.mp1 = MessagePassing(hidden_dim, hidden_dim)\n",
        "        self.mp2 = MessagePassing(hidden_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, 1, bias=False)\n",
        "        self.fc4 = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_dim)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, adj, items, last_item, idx):\n",
        "        \n",
        "        ############## Task 10\n",
        "    \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "        \n",
        "        e = self.embedding(items)\n",
        "        h = self.relu(self.mp1(adj,e))\n",
        "        h = self.dropout(h)\n",
        "        z = self.mp2(adj,h)\n",
        "        z = self.dropout(z)\n",
        "        sl = z[last_item, :]\n",
        "\n",
        "\n",
        "        \n",
        "        q1 = self.fc1(sl)\n",
        "        q1 = torch.index_select(q1, 0, idx)\n",
        "        q2 = self.fc2(z)\n",
        "        alpha = self.fc3(torch.sigmoid(q1 + q2))\n",
        "        z = alpha*z\n",
        "        idx = idx.unsqueeze(1).repeat(1, z.size(1))\n",
        "        out = torch.zeros(last_item.size(0), z.size(1)).to(self.device)\n",
        "        sg = out.scatter_add_(0, idx, z)\n",
        "        sg = self.dropout(sg)\n",
        "\n",
        "        \n",
        "        ##################\n",
        "        # your code here #\n",
        "        ##################\n",
        "\n",
        "        s = torch.cat((sg, sl), dim = 1)\n",
        "        s = self.fc4(s)\n",
        "\n",
        "\n",
        "        #out = torch.mm(s, e)\n",
        "\n",
        "        E = self.embedding.weight[1:, :]\n",
        "        out = torch.mm(s,E.t())\n",
        "        #concatenate sg and sl\n",
        "        #pass through fc4\n",
        "        #inner product of each embedding with the output of fc4\n",
        "        #return softmax \n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ64t4swdzzy",
        "outputId": "f0296215-4a4d-4777-ad18-458e6b48ce34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training sessions 719470\n",
            "number of testing sessions 60858\n",
            "number of unique items in the trainset 42973\n",
            "max id 43096 min 1\n",
            "len of the longest session 40\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Graph-based Recommendations - ALTEGRAD - Jan 2022\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Initializes device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Loads training and test data\n",
        "sessions_train, sessions_test, y_train, y_test, max_item_id = load_dataset()\n",
        "\n",
        "# Generates batches\n",
        "adj_train, items_train, last_item_train, idx_train, targets_train = generate_batches(sessions_train, y_train, batch_size=256, device=device)\n",
        "adj_test, items_test, last_item_test, idx_test, targets_test = generate_batches(sessions_test, y_test, batch_size=256, device=device)\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 30\n",
        "hidden_dim = 64\n",
        "dropout = 0.0\n",
        "learning_rate = 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYK5mCat3XZf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "outputId": "81d1b85a-0720-4ba3-c217-7764797d7ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 loss_train: 8.5369 time: 570.7989s\n",
            "Best Results on Test Set:\n",
            "Recall@20: 27.5313 MMR@20: 7.5957\n",
            "-------------------------------------------------------\n",
            "\n",
            "Epoch: 02 loss_train: 6.5375 time: 612.3839s\n",
            "Best Results on Test Set:\n",
            "Recall@20: 38.6901 MMR@20: 11.3190\n",
            "-------------------------------------------------------\n",
            "\n",
            "Epoch: 03 loss_train: 5.7755 time: 584.5933s\n",
            "Best Results on Test Set:\n",
            "Recall@20: 43.8283 MMR@20: 13.1827\n",
            "-------------------------------------------------------\n",
            "\n",
            "Epoch: 04 loss_train: 5.4055 time: 563.8418s\n",
            "Best Results on Test Set:\n",
            "Recall@20: 45.5585 MMR@20: 13.9046\n",
            "-------------------------------------------------------\n",
            "\n",
            "Epoch: 05 loss_train: 5.1766 time: 552.7189s\n",
            "Best Results on Test Set:\n",
            "Recall@20: 45.8033 MMR@20: 14.0490\n",
            "-------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-32072fb5da1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_item_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = SR_GNN(max_item_id+2, hidden_dim, dropout, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Trains and evaluates the SR-GNN model\n",
        "start = time.time()\n",
        "best_results = {'hit': {'val':0, 'epoch': 0}, 'mrr': {'val':0, 'epoch': 0}}\n",
        "for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    count = 0\n",
        "    n_train_batches = len(adj_train)\n",
        "    for i in range(n_train_batches):\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(adj_train[i], items_train[i], last_item_train[i], idx_train[i])\n",
        "        loss = loss_function(scores, targets_train[i]-1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * scores.size(0)\n",
        "        count += scores.size(0)\n",
        "            \n",
        "    print('Epoch: {:02d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(train_loss / count),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "    \n",
        "    model.eval()\n",
        "    hit, mrr = [], []\n",
        "    n_test_batches = len(adj_test)\n",
        "    for i in range(n_test_batches):\n",
        "        scores = model(adj_test[i], items_test[i], last_item_test[i], idx_test[i])\n",
        "        sub_scores = scores.topk(20)[1]\n",
        "        sub_scores = sub_scores.detach().cpu().numpy()\n",
        "        for score, target in zip(sub_scores, targets_test[i]):\n",
        "            target = target.cpu().numpy()\n",
        "            hit.append(np.isin(target-1, score))\n",
        "            if len(np.where(score == target-1)[0]) == 0:\n",
        "                mrr.append(0)\n",
        "            else:\n",
        "                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
        "    \n",
        "    hit = np.mean(hit)*100\n",
        "    if hit >= best_results['hit']['val']:\n",
        "        best_results['hit']['val'] = hit\n",
        "        best_results['hit']['epoch'] = epoch\n",
        "   \n",
        "    mrr = np.mean(mrr)*100\n",
        "    if mrr >= best_results['mrr']['val']:\n",
        "        best_results['mrr']['val'] = mrr\n",
        "        best_results['mrr']['epoch'] = epoch\n",
        "        \n",
        "    print('Best Results on Test Set:')\n",
        "    print('Recall@20: {:.4f}'.format(best_results['hit']['val']),\n",
        "          'MMR@20: {:.4f}'.format(best_results['mrr']['val']))\n",
        "    print('-------------------------------------------------------')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**note:** Training took too much time,  I haven't finished it."
      ],
      "metadata": {
        "id": "Z10hPWs1FnvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wF0iUn30a0uA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ALTEGRAD_TP7_Lacombe_Yoach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}