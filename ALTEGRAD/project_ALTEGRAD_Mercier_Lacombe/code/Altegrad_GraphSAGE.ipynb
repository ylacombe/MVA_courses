{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Altegrad_GraphSAGE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F-nVqxw1rR7p",
        "EVurQzgjVntH",
        "RcubUI-VeifG"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load data and graph"
      ],
      "metadata": {
        "id": "DEILrPpHod1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n"
      ],
      "metadata": {
        "id": "tAQVAjKfwRDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import random\n",
        "import csv\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import plot_importance\n",
        "\n",
        "PATH = '/content/drive/MyDrive/mva/Altegrad/'\n",
        "EDGE_LIST_PATH = PATH +'citation-prediction-altegrad/edgelist.txt'\n",
        "AUTHORS_LIST_PATH = PATH +'citation-prediction-altegrad/authors.txt'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "AFyqmR6g5Qe3",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:15.913543Z",
          "iopub.execute_input": "2022-02-09T22:09:15.913938Z",
          "iopub.status.idle": "2022-02-09T22:09:17.176860Z",
          "shell.execute_reply.started": "2022-02-09T22:09:15.913850Z",
          "shell.execute_reply": "2022-02-09T22:09:17.176065Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import plot_confusion_matrix, log_loss, accuracy_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import smart_open\n",
        "import gensim\n",
        "\n",
        "def read_corpus(fname, tokens_only=False):\n",
        "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            tokens = gensim.utils.simple_preprocess(line)\n",
        "            if tokens_only:\n",
        "                yield tokens\n",
        "            else:\n",
        "                # For training data, add tags\n",
        "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "def other_metrics(graph, edges):\n",
        "    similarity_dice = graph.similarity_dice(pairs = edges)\n",
        "    similarity_jaccard = graph.similarity_jaccard(pairs = edges)\n",
        "    return similarity_dice, similarity_jaccard\n",
        "\n",
        "def evaluate_estimator(clf, X_test, y_test):\n",
        "    plot_confusion_matrix(clf, X_test, y_test)\n",
        "    plt.show()\n",
        "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
        "    print(\"accuracy\",accuracy_score(y_test, (y_pred>0.5)))\n",
        "    print(\"log_loss\", log_loss(y_test, y_pred, eps=1e-7))\n",
        "    print(\"auc\", roc_auc_score(y_test, y_pred))\n",
        "    plt.hist(y_pred)\n",
        "    plt.show()\n",
        "    "
      ],
      "metadata": {
        "id": "Inb2EkzR5QfC",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:17.178517Z",
          "iopub.execute_input": "2022-02-09T22:09:17.180290Z",
          "iopub.status.idle": "2022-02-09T22:09:17.398337Z",
          "shell.execute_reply.started": "2022-02-09T22:09:17.180256Z",
          "shell.execute_reply": "2022-02-09T22:09:17.397625Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGL import"
      ],
      "metadata": {
        "id": "rrjdEZzO85WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install dgl"
      ],
      "metadata": {
        "id": "Ze06o9RR-Exd",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:58.375568Z",
          "iopub.execute_input": "2022-02-09T22:09:58.377563Z",
          "iopub.status.idle": "2022-02-09T22:09:58.381029Z",
          "shell.execute_reply.started": "2022-02-09T22:09:58.377530Z",
          "shell.execute_reply": "2022-02-09T22:09:58.380314Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl-cu110 -f https://data.dgl.ai/wheels/repo.html"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:58.382331Z",
          "iopub.execute_input": "2022-02-09T22:09:58.383088Z",
          "iopub.status.idle": "2022-02-09T22:10:18.948146Z",
          "shell.execute_reply.started": "2022-02-09T22:09:58.383052Z",
          "shell.execute_reply": "2022-02-09T22:10:18.947330Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahmethxq_J9z",
        "outputId": "2474b072-d083-43a6-a57e-2a844d436c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu110\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu110-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (143.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 143.5 MB 7.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (1.21.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (3.0.4)\n",
            "Installing collected packages: dgl-cu110\n",
            "Successfully installed dgl-cu110-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from dgl.nn import SAGEConv\n",
        "import dgl.function as fn\n",
        "import torch"
      ],
      "metadata": {
        "id": "XGZmcZex844y",
        "outputId": "6faed27a-0bd0-453d-e267-2b8c4998e0cf",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:10:18.950571Z",
          "iopub.execute_input": "2022-02-09T22:10:18.950858Z",
          "iopub.status.idle": "2022-02-09T22:10:21.449131Z",
          "shell.execute_reply.started": "2022-02-09T22:10:18.950818Z",
          "shell.execute_reply": "2022-02-09T22:10:21.448448Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-09T22:10:21.453304Z",
          "iopub.execute_input": "2022-02-09T22:10:21.455349Z",
          "iopub.status.idle": "2022-02-09T22:10:21.512504Z",
          "shell.execute_reply.started": "2022-02-09T22:10:21.455309Z",
          "shell.execute_reply": "2022-02-09T22:10:21.511581Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4KxclAP_J90",
        "outputId": "83a6bbc0-41e5-4eca-95bd-7e5b7dfc26e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load graph"
      ],
      "metadata": {
        "id": "szVr7j_v5Qe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "T9TUr41jW3Hl",
        "outputId": "896726bb-b5f2-490a-8e76-43e997205db6",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:17.401297Z",
          "iopub.execute_input": "2022-02-09T22:09:17.401502Z",
          "iopub.status.idle": "2022-02-09T22:09:17.406457Z",
          "shell.execute_reply.started": "2022-02-09T22:09:17.401471Z",
          "shell.execute_reply": "2022-02-09T22:09:17.405779Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a graph\n",
        "G = nx.read_edgelist(EDGE_LIST_PATH, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
        "nodes = list(G.nodes())\n",
        "n = G.number_of_nodes()\n",
        "m = G.number_of_edges()\n",
        "print('Number of nodes:', n)\n",
        "print('Number of edges:', m)"
      ],
      "metadata": {
        "id": "WzfjcLjA5Qe8",
        "outputId": "94763826-77d4-4409-adec-e72a6fb4a744",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:17.408259Z",
          "iopub.execute_input": "2022-02-09T22:09:17.408815Z",
          "iopub.status.idle": "2022-02-09T22:09:23.631798Z",
          "shell.execute_reply.started": "2022-02-09T22:09:17.408779Z",
          "shell.execute_reply": "2022-02-09T22:09:23.630155Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 138499\n",
            "Number of edges: 1091955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative edges"
      ],
      "metadata": {
        "id": "h-vECMsAobYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Create **negative edges** with random sampling of pair of nodes"
      ],
      "metadata": {
        "id": "XjSrmTSV5Qe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_G = nx.read_edgelist(PATH+'negative_edgelist.txt', delimiter=',', nodetype=int)\n",
        "\n",
        "\n",
        "print('Number of nodes:', neg_G.number_of_nodes())\n",
        "print('Number of edges:', neg_G.number_of_edges())"
      ],
      "metadata": {
        "id": "nu9bBqTZ5Qe-",
        "outputId": "9a6fccf8-413f-43c6-e5be-858dd272f35c",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:39.686513Z",
          "iopub.execute_input": "2022-02-09T22:09:39.688457Z",
          "iopub.status.idle": "2022-02-09T22:09:53.328910Z",
          "shell.execute_reply.started": "2022-02-09T22:09:39.688425Z",
          "shell.execute_reply": "2022-02-09T22:09:53.328140Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 138499\n",
            "Number of edges: 1456999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_negative_edges(G, m):\n",
        "    f = open(PATH +\"negative_edgelist.txt\", \"w\")\n",
        "    my_set = list(neg_G.edges())\n",
        "    n = G.number_of_nodes()\n",
        "    edges = list(G.edges())\n",
        "    string = ''\n",
        "    for edge in my_set:\n",
        "        n1, n2 = edge\n",
        "        string +=str(n1) +',' +str(n2)+'\\n'\n",
        "\n",
        "    while len(my_set)<m:\n",
        "        n1 = nodes[randint(0, n-1)]\n",
        "        n2 = nodes[randint(0, n-1)]\n",
        "        while ((n1,n2) in my_set or (n2,n1) in my_set) or ((n1,n2) in edges or (n2,n1) in edges):\n",
        "            n2 = nodes[randint(0, n-1)]\n",
        "        my_set.append((n1,n2))\n",
        "        string += str(n1) +',' +str(n2)+'\\n'\n",
        "\n",
        "        if len(my_set)%10000==0:\n",
        "            f.write(string)\n",
        "            string = ''\n",
        "\n",
        "    f.close() \n",
        "    del my_set\n",
        "\n",
        "#generate_negative_edges(G, m=3*G.number_of_edges())"
      ],
      "metadata": {
        "id": "UOElSpVDUf2L",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:23.634425Z",
          "iopub.execute_input": "2022-02-09T22:09:23.634718Z",
          "iopub.status.idle": "2022-02-09T22:09:39.685299Z",
          "shell.execute_reply.started": "2022-02-09T22:09:23.634676Z",
          "shell.execute_reply": "2022-02-09T22:09:39.684527Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Embeddings\n",
        "\n",
        "Create node embeddings for every research paper on the dataset. \n",
        "Include research on authors embeddings.\n",
        "\n",
        "Split dataset."
      ],
      "metadata": {
        "id": "aRNrQxWAF9a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create nodes features"
      ],
      "metadata": {
        "id": "atVujq3patNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Authors Graph\n",
        "\n",
        "We use the author graph to create node embeddings. We tried hot-autoencoder and random walks with different libraries."
      ],
      "metadata": {
        "id": "ukovSzlECemI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qny6ZbLpgHD0",
        "outputId": "9efa7f6e-415b-4f1f-aec1-d46803302421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 7.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import csv\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import unidecode\n",
        "\n",
        "\n",
        "regex = re.compile('[^a-zA-Z ,]')\n",
        "\n",
        "def process_author(s):\n",
        "    l = s.split()\n",
        "    l = [m[:3].upper() for m in l]\n",
        "    return ' '.join(l)\n",
        "\n",
        "def process_authors_split(s):\n",
        "    s = s.replace('Janne Heikkil #x E', 'Janne Heikkila')\n",
        "    s = s.replace('Samuel Rota Bul #x F', \"Samuel Rota Bulo\")\n",
        "    s = s.replace('Maria Salam #x F,Llorente', 'Maria Salamo Llorente')\n",
        "    s = s.replace('Patrick H #x E,as,dric Herzet', 'Patrick Heas, Cedric Herzet')\n",
        "    s = s.replace('Etienne M #x E,min', 'Etienne Memin')\n",
        "    s = regex.sub('', s)\n",
        "    \n",
        "    authors_split = s.split(',')\n",
        "    authors_split = [process_author(a) for a in authors_split]\n",
        "    \n",
        "    return authors_split\n",
        "\n",
        "authors_per_node = [] # for hot encoder\n",
        "author_dic = {} # attribute a number to all authors\n",
        "count_authors = 0\n",
        "\n",
        "with open(AUTHORS_LIST_PATH, 'r', errors = 'strict') as f:\n",
        "    for line in f:\n",
        "        #do stuff\n",
        "        node, authors = line.split('|--|')\n",
        "        \n",
        "        #process errors\n",
        "        authors = unidecode.unidecode(authors)\n",
        "\n",
        "        #', -'\n",
        "        authors_split = process_authors_split(authors)\n",
        "        authors_node = []\n",
        "\n",
        "        for author in authors_split:\n",
        "            if author not in author_dic.keys():\n",
        "                author_dic[author] = count_authors\n",
        "                count_authors += 1\n",
        "            authors_node.append(author_dic[author])\n",
        "        authors_per_node.append(authors_node)\n",
        "\n",
        "max_author_per_node = max([len(authors_per_node[i]) for i in range(len(authors_per_node))])"
      ],
      "metadata": {
        "id": "vi9_r16CavOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Random walk with stellarGraph\n"
      ],
      "metadata": {
        "id": "hr5CofLXihKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install stellargraph"
      ],
      "metadata": {
        "id": "WcNlPbDQjdJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "authors_G = nx.Graph()\n",
        "\n",
        "edges = G.edges()\n",
        "for edge in edges:\n",
        "    n1, n2 = edge\n",
        "    for author1 in authors_per_node[n1]:\n",
        "        for author2 in authors_per_node[n2]:\n",
        "            if authors_G.has_edge(author1, author2):\n",
        "                # we added this one before, just increase the weight by one\n",
        "                authors_G[author1][author2]['weight'] += 1\n",
        "            else:\n",
        "                # new edge. add with weight=1\n",
        "                authors_G.add_edge(author1, author2, weight=1)\n",
        "print(\"graph authors done\")\n",
        "print(\"authors edges\",authors_G.number_of_edges())\n",
        "print(\"authors nodes\",authors_G.number_of_nodes())\n",
        "\n",
        "n_authors = authors_G.number_of_nodes()\n",
        "\n",
        "del authors_per_node, G, author_dic\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "sBb8BltOhunE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author_graph = StellarGraph.from_networkx(authors_G)\n",
        "\n",
        "rw = BiasedRandomWalk(author_graph)\n",
        "\n",
        "walks = rw.run(\n",
        "    nodes=list(author_graph.nodes()),  # root nodes\n",
        "    length=100,  # maximum length of a random walk\n",
        "    n=10,  # number of random walks per root node\n",
        "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        ")\n",
        "print(\"Number of random walks: {}\".format(len(walks)))\n",
        "\n",
        "str_walks = [[str(n) for n in walk] for walk in walks]\n",
        "model = Word2Vec(str_walks, size=128, window=5, min_count=0, sg=1, workers=2, iter=1)\n",
        "\n",
        "node_ids = [int(id) for id in model.wv.index2word]  # list of node IDs\n",
        "mixed_authors_embeddings = (model.wv.vectors)  \n",
        "authors_embeddings = np.array([emb for _,emb in sorted(zip(node_ids,mixed_authors_embeddings))])\n",
        "\n",
        "def get_node_embedding(node, vecs=authors_embeddings):\n",
        "    authors = authors_per_node[node]\n",
        "\n",
        "    emb_node = np.mean([vecs[i] for i in authors], axis = 0)\n",
        "    return emb_node"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYwi6seuiq7h",
        "outputId": "ab016889-8269-4838-d422-ff0bbb51306e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of random walks: 1062010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_node_embedding_from_authors(node, vecs=authors_embeddings):\n",
        "    authors = authors_per_node[node]\n",
        "    emb_node = np.mean([vecs[i] for i in authors], axis = 0)\n",
        "    return emb_node"
      ],
      "metadata": {
        "id": "6O1Ew-7XnxZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"embeddingAUTHORS.npy\", 'wb') as f:\n",
        "    np.save(f, authors_embeddings)"
      ],
      "metadata": {
        "id": "Nlc5ad__lT3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Random walk with DGL"
      ],
      "metadata": {
        "id": "C8zfRYelic8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges = G.edges()\n",
        "u, v = list(), list()\n",
        "for edge in edges:\n",
        "    n1, n2 = edge\n",
        "    for author1 in authors_per_node[n1]:\n",
        "        for author2 in authors_per_node[n2]:\n",
        "            u.append(author1)\n",
        "            v.append(author2)\n",
        "\n",
        "authors_graph = dgl.graph((torch.tensor(u), torch.tensor(v)))\n",
        "\n",
        "def authors_rw(node, size=20, l=5):\n",
        "    encoder = []\n",
        "    for i in range(size//l):\n",
        "        start = np.random.choice(authors_per_node[node])\n",
        "        next = dgl.sampling.node2vec_random_walk(authors_graph, start, 1, 1, l)\n",
        "        for i in range(1,len(next[0])):\n",
        "            encoder.append(int(next[0][i].detach()))\n",
        "    return encoder\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MzK3idZYmIRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add node features\n",
        "\n",
        "Add doc2vec and use results,\n",
        "Add author embedding,\n",
        "and some basic node features."
      ],
      "metadata": {
        "id": "jWnEudXoOoFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenght_rw = 21\n",
        "lenght = 3\n",
        "\n",
        "node_features = np.zeros((n, 514+512+128))\n",
        "\n",
        "with open(PATH+'doc2vec_emb.npy', 'rb') as f:\n",
        "      vecs = np.load(f)\n",
        "\n",
        "with open(PATH+'USE_embedding.npy', 'rb') as f:\n",
        "      use = np.load(f)\n",
        "\n",
        "for i, node in enumerate(G.nodes):\n",
        "    node_features[i, 0] = G.degree(node) # degree of the node\n",
        "    node_features[i, 1] = len(authors_per_node[i]) # number of authors\n",
        "    node_features[i, 2:514] = vecs[i] # Word2vec abstract embedding\n",
        "    node_features[i, 514:514+512] = use[i] # Use abstract embedding\n",
        "    node_features[i, 514+512:] = get_node_embedding_from_authors(node) # node2vec authorgraph with stellagraph, with dgl use : authors_rw(node, size=lenght_rw, l=lenght)\n",
        "\n",
        "del authors_per_node, author_dic"
      ],
      "metadata": {
        "id": "Tp_pma14D-CJ",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:09:53.330338Z",
          "iopub.execute_input": "2022-02-09T22:09:53.330588Z",
          "iopub.status.idle": "2022-02-09T22:09:58.374361Z",
          "shell.execute_reply.started": "2022-02-09T22:09:53.330553Z",
          "shell.execute_reply": "2022-02-09T22:09:58.373571Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split and prepare dataset"
      ],
      "metadata": {
        "id": "5ZTq6EcZoJ0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.ndarray import cpu\n",
        "random.seed(10)\n",
        "test_size = int(G.number_of_edges() * 0.1)\n",
        "train_size = G.number_of_edges() - test_size\n",
        "\n",
        "# Split edge set for training and testing\n",
        "g = dgl.from_networkx(G).to(device)\n",
        "u, v = g.edges()\n",
        "eids = np.random.permutation(np.arange(g.number_of_edges()))\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Same with negative edges\n",
        "test_size = test_size # int(neg_G.number_of_edges() * 0.1)\n",
        "neg_g = dgl.from_networkx(neg_G)\n",
        "neg_u, neg_v = neg_g.edges()\n",
        "neg_eids = np.random.permutation(np.arange(len(neg_u)))\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
        "\n",
        "del neg_u, neg_v, neg_eids\n",
        "del u, v, eids"
      ],
      "metadata": {
        "id": "N_FwgzzIwng3",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:10:21.516670Z",
          "iopub.execute_input": "2022-02-09T22:10:21.516936Z",
          "iopub.status.idle": "2022-02-09T22:11:53.511663Z",
          "shell.execute_reply.started": "2022-02-09T22:10:21.516901Z",
          "shell.execute_reply": "2022-02-09T22:11:53.506715Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(PATH+\"train_test_split.npy\", 'wb') as f:\n",
        "    np.save(f, train_pos_u.cpu().detach().numpy())\n",
        "    np.save(f, train_pos_v.cpu().detach().numpy())\n",
        "    np.save(f, train_neg_u.cpu().detach().numpy())\n",
        "    np.save(f, train_neg_v.cpu().detach().numpy())\n",
        "    \n",
        "    np.save(f, test_pos_u.cpu().detach().numpy())\n",
        "    np.save(f, test_pos_v.cpu().detach().numpy())\n",
        "    np.save(f, test_neg_u.cpu().detach().numpy())\n",
        "    np.save(f, test_neg_v.cpu().detach().numpy())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-09T22:11:53.512882Z",
          "iopub.execute_input": "2022-02-09T22:11:53.513137Z",
          "iopub.status.idle": "2022-02-09T22:11:53.604883Z",
          "shell.execute_reply.started": "2022-02-09T22:11:53.513102Z",
          "shell.execute_reply": "2022-02-09T22:11:53.604155Z"
        },
        "trusted": true,
        "id": "2zzgPOBX_J91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --------- 1. Prepare dataset ------------- #\n",
        "\n",
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes()).to(device)\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes()).to(device)\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes()).to(device)\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes()).to(device)\n",
        "\n",
        "del train_neg_v, train_neg_u, train_pos_v, train_pos_u\n",
        "\n",
        "\n",
        "# Add node features to graphs\n",
        "train_pos_g.ndata['feat'] = torch.tensor(node_features).type(torch.float32).to(device)\n",
        "g.ndata['feat'] = torch.tensor(node_features).type(torch.float32).to(device)"
      ],
      "metadata": {
        "id": "77a8zzfCqkii",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:11:53.608052Z",
          "iopub.execute_input": "2022-02-09T22:11:53.608353Z",
          "iopub.status.idle": "2022-02-09T22:11:54.864602Z",
          "shell.execute_reply.started": "2022-02-09T22:11:53.608316Z",
          "shell.execute_reply": "2022-02-09T22:11:54.863841Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE\n",
        "\n",
        "Train a CraphSAGE embedding, with a MLP."
      ],
      "metadata": {
        "id": "QmpsB9PQ8z8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "def compute_loss(pos_score, neg_score, weights=None,device = device):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).to(device)\n",
        "    return F.binary_cross_entropy(scores, labels,weight=weights)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).cpu().detach().numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().detach().numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats * 5)\n",
        "        self.W2 = nn.Linear(h_feats * 5, h_feats)\n",
        "        self.W3 = nn.Linear(h_feats, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.drop1 = nn.Dropout(p=0.5)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        output =  self.sig(self.W3(F.relu(self.W2(self.drop1(F.relu(self.W1(h)))))))\n",
        "        return {'score': output.squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']\n",
        "\n",
        "    def output(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges_test)\n",
        "            return g.edata['score']\n",
        "\n",
        "    def apply_edges_test(self, edges):\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        output =  self.sig(self.W3(F.relu(self.W2(F.relu(self.W1(h))))))\n",
        "        return {'score': output.squeeze(1)}"
      ],
      "metadata": {
        "id": "4y0uJ2RX7tse",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:11:54.866103Z",
          "iopub.execute_input": "2022-02-09T22:11:54.866385Z",
          "iopub.status.idle": "2022-02-09T22:11:54.882733Z",
          "shell.execute_reply.started": "2022-02-09T22:11:54.866350Z",
          "shell.execute_reply": "2022-02-09T22:11:54.881682Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- Parameters -------------- #\n",
        "nepochs = 500\n",
        "milestones = np.arange(0, nepochs, 450)\n",
        "lr = 0.01\n",
        "gamma = 0.5\n",
        "hidden_dim = 32\n",
        "\n",
        "\n",
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "model = GraphSAGE(train_pos_g.ndata['feat'].shape[1], hidden_dim).to(device)\n",
        "pred = MLPPredictor(hidden_dim).to(device)\n",
        "# in this case, loss in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=lr)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "\n",
        "validation_scores = []\n",
        "training_scores = []\n",
        "min_loss = np.infty\n",
        "for e in range(nepochs):\n",
        "    # forward\n",
        "    h = model(train_pos_g, train_pos_g.ndata['feat'])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    # weights = torch.cat([2*torch.ones(pos_score.shape[0]), torch.ones(neg_score.shape[0])]).to(device)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "    \n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "  \n",
        "    pos_score = pred.output(test_pos_g, h)\n",
        "    neg_score = pred.output(test_neg_g, h)\n",
        "    val_loss = compute_loss(pos_score, neg_score)\n",
        "    training_scores.append(loss.cpu().detach().numpy())\n",
        "    validation_scores.append(val_loss.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, training loss: {}, validation loss: {}'.format(e, loss, val_loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print('AUC', compute_auc(pos_score, neg_score))\n",
        "\n",
        "plt.plot(np.arange(nepochs), validation_scores, label='val')\n",
        "plt.plot(np.arange(nepochs), training_scores, label='train')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"score\")\n",
        "plt.title('Scores through training')"
      ],
      "metadata": {
        "id": "FcinO1lbqTUl",
        "outputId": "d5c9e9eb-0458-4374-eda0-8a6643c94a01",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:11:54.884066Z",
          "iopub.execute_input": "2022-02-09T22:11:54.885319Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, training loss: 0.7733775973320007, validation loss: 1.3882930278778076\n",
            "In epoch 5, training loss: 0.6782967448234558, validation loss: 0.6902710199356079\n",
            "In epoch 10, training loss: 0.6786903738975525, validation loss: 0.6952411532402039\n",
            "In epoch 15, training loss: 0.6650831699371338, validation loss: 0.6747903227806091\n",
            "In epoch 20, training loss: 0.6443881988525391, validation loss: 0.6649748086929321\n",
            "In epoch 25, training loss: 0.610381543636322, validation loss: 0.6235160231590271\n",
            "In epoch 30, training loss: 0.5574725270271301, validation loss: 0.5651547908782959\n",
            "In epoch 35, training loss: 0.5056649446487427, validation loss: 0.5192344188690186\n",
            "In epoch 40, training loss: 0.4624592363834381, validation loss: 0.481560081243515\n",
            "In epoch 45, training loss: 0.43866124749183655, validation loss: 0.44334670901298523\n",
            "In epoch 50, training loss: 0.40619194507598877, validation loss: 0.44532597064971924\n",
            "In epoch 55, training loss: 0.3803980052471161, validation loss: 0.39756447076797485\n",
            "In epoch 60, training loss: 0.3577374219894409, validation loss: 0.3899292051792145\n",
            "In epoch 65, training loss: 0.33736151456832886, validation loss: 0.35288164019584656\n",
            "In epoch 70, training loss: 0.31229519844055176, validation loss: 0.33909133076667786\n",
            "In epoch 75, training loss: 0.2856628894805908, validation loss: 0.35090863704681396\n",
            "In epoch 80, training loss: 0.27898046374320984, validation loss: 0.3094857633113861\n",
            "In epoch 85, training loss: 0.2654009461402893, validation loss: 0.31599298119544983\n",
            "In epoch 90, training loss: 0.24814783036708832, validation loss: 0.28037118911743164\n",
            "In epoch 95, training loss: 0.23623959720134735, validation loss: 0.2947673797607422\n",
            "In epoch 100, training loss: 0.22939549386501312, validation loss: 0.27612754702568054\n",
            "In epoch 105, training loss: 0.2230335772037506, validation loss: 0.28318482637405396\n",
            "In epoch 110, training loss: 0.2174282968044281, validation loss: 0.2674574851989746\n",
            "In epoch 115, training loss: 0.21245625615119934, validation loss: 0.26836690306663513\n",
            "In epoch 120, training loss: 0.20623739063739777, validation loss: 0.26573601365089417\n",
            "In epoch 125, training loss: 0.20153725147247314, validation loss: 0.2526162266731262\n",
            "In epoch 130, training loss: 0.1969117522239685, validation loss: 0.2487775981426239\n",
            "In epoch 135, training loss: 0.187822163105011, validation loss: 0.25825923681259155\n",
            "In epoch 140, training loss: 0.18267758190631866, validation loss: 0.24222342669963837\n",
            "In epoch 145, training loss: 0.17778512835502625, validation loss: 0.23583672940731049\n",
            "In epoch 150, training loss: 0.17201858758926392, validation loss: 0.23682411015033722\n",
            "In epoch 155, training loss: 0.16580021381378174, validation loss: 0.23588663339614868\n",
            "In epoch 160, training loss: 0.16726942360401154, validation loss: 0.2263495922088623\n",
            "In epoch 165, training loss: 0.16767364740371704, validation loss: 0.23279523849487305\n",
            "In epoch 170, training loss: 0.16004234552383423, validation loss: 0.22243231534957886\n",
            "In epoch 175, training loss: 0.15447960793972015, validation loss: 0.21469244360923767\n",
            "In epoch 180, training loss: 0.15274153649806976, validation loss: 0.21948213875293732\n",
            "In epoch 185, training loss: 0.14942574501037598, validation loss: 0.22134624421596527\n",
            "In epoch 190, training loss: 0.14623965322971344, validation loss: 0.21746359765529633\n",
            "In epoch 195, training loss: 0.14296786487102509, validation loss: 0.21383769810199738\n",
            "In epoch 200, training loss: 0.18889907002449036, validation loss: 0.1971726417541504\n",
            "In epoch 205, training loss: 0.15537646412849426, validation loss: 0.23517699539661407\n",
            "In epoch 210, training loss: 0.14700113236904144, validation loss: 0.20778712630271912\n",
            "In epoch 215, training loss: 0.14080949127674103, validation loss: 0.1957627236843109\n",
            "In epoch 220, training loss: 0.1367463767528534, validation loss: 0.20467621088027954\n",
            "In epoch 225, training loss: 0.1349191963672638, validation loss: 0.19713328778743744\n",
            "In epoch 230, training loss: 0.1327642798423767, validation loss: 0.2005222588777542\n",
            "In epoch 235, training loss: 0.1311073750257492, validation loss: 0.19688713550567627\n",
            "In epoch 240, training loss: 0.12930545210838318, validation loss: 0.1960815191268921\n",
            "In epoch 245, training loss: 0.1280912458896637, validation loss: 0.1962205320596695\n",
            "In epoch 250, training loss: 0.1269731968641281, validation loss: 0.19565364718437195\n",
            "In epoch 255, training loss: 0.12586377561092377, validation loss: 0.1940048187971115\n",
            "In epoch 260, training loss: 0.12480010092258453, validation loss: 0.19278331100940704\n",
            "In epoch 265, training loss: 0.1237373799085617, validation loss: 0.19091780483722687\n",
            "In epoch 270, training loss: 0.12287577241659164, validation loss: 0.1907563954591751\n",
            "In epoch 275, training loss: 0.13708974421024323, validation loss: 0.18015408515930176\n",
            "In epoch 280, training loss: 0.12387347966432571, validation loss: 0.17424887418746948\n",
            "In epoch 285, training loss: 0.12395478785037994, validation loss: 0.1952708661556244\n",
            "In epoch 290, training loss: 0.12182104587554932, validation loss: 0.18252193927764893\n",
            "In epoch 295, training loss: 0.11974281072616577, validation loss: 0.1800236850976944\n",
            "In epoch 300, training loss: 0.11869432032108307, validation loss: 0.183389812707901\n",
            "In epoch 305, training loss: 0.11784323304891586, validation loss: 0.18369460105895996\n",
            "In epoch 310, training loss: 0.11671604961156845, validation loss: 0.18307210505008698\n",
            "In epoch 315, training loss: 0.11560863256454468, validation loss: 0.18113428354263306\n",
            "In epoch 320, training loss: 0.11482369154691696, validation loss: 0.18039600551128387\n",
            "In epoch 325, training loss: 0.11833617836236954, validation loss: 0.1834821105003357\n",
            "In epoch 330, training loss: 0.11736517399549484, validation loss: 0.18008248507976532\n",
            "In epoch 335, training loss: 0.11314952373504639, validation loss: 0.18549692630767822\n",
            "In epoch 340, training loss: 0.11556506901979446, validation loss: 0.16635452210903168\n",
            "In epoch 345, training loss: 0.11289399117231369, validation loss: 0.17732128500938416\n",
            "In epoch 350, training loss: 0.11025650799274445, validation loss: 0.1802358329296112\n",
            "In epoch 355, training loss: 0.11186286807060242, validation loss: 0.16693903505802155\n",
            "In epoch 360, training loss: 0.10851962119340897, validation loss: 0.17109136283397675\n",
            "In epoch 365, training loss: 0.1085742935538292, validation loss: 0.17577245831489563\n",
            "In epoch 370, training loss: 0.10769656300544739, validation loss: 0.17612290382385254\n",
            "In epoch 375, training loss: 0.10689537227153778, validation loss: 0.1749277412891388\n",
            "In epoch 380, training loss: 0.10551692545413971, validation loss: 0.17221306264400482\n",
            "In epoch 385, training loss: 0.10705866664648056, validation loss: 0.1678246408700943\n",
            "In epoch 390, training loss: 0.10429305583238602, validation loss: 0.17327283322811127\n",
            "In epoch 395, training loss: 0.1049133911728859, validation loss: 0.17412520945072174\n",
            "In epoch 400, training loss: 0.10388810187578201, validation loss: 0.17201167345046997\n",
            "In epoch 405, training loss: 0.10325378179550171, validation loss: 0.1650894731283188\n",
            "In epoch 410, training loss: 0.1026836708188057, validation loss: 0.16771745681762695\n",
            "In epoch 415, training loss: 0.10837201774120331, validation loss: 0.17434044182300568\n",
            "In epoch 420, training loss: 0.10377248376607895, validation loss: 0.17318584024906158\n",
            "In epoch 425, training loss: 0.10085160285234451, validation loss: 0.16954495012760162\n",
            "In epoch 430, training loss: 0.10117059201002121, validation loss: 0.16429945826530457\n",
            "In epoch 435, training loss: 0.10036206245422363, validation loss: 0.16353033483028412\n",
            "In epoch 440, training loss: 0.09930204600095749, validation loss: 0.16668865084648132\n",
            "In epoch 445, training loss: 0.09933347254991531, validation loss: 0.16771838068962097\n",
            "In epoch 450, training loss: 0.09838255494832993, validation loss: 0.16566599905490875\n",
            "In epoch 455, training loss: 0.1006285697221756, validation loss: 0.16122333705425262\n",
            "In epoch 460, training loss: 0.09782710671424866, validation loss: 0.16697447001934052\n",
            "In epoch 465, training loss: 0.10018786787986755, validation loss: 0.15570253133773804\n",
            "In epoch 470, training loss: 0.09699837863445282, validation loss: 0.15788534283638\n",
            "In epoch 475, training loss: 0.09661400318145752, validation loss: 0.1610783189535141\n",
            "In epoch 480, training loss: 0.09611741453409195, validation loss: 0.16140978038311005\n",
            "In epoch 485, training loss: 0.09554489701986313, validation loss: 0.1602693498134613\n",
            "In epoch 490, training loss: 0.09575829654932022, validation loss: 0.1588982492685318\n",
            "In epoch 495, training loss: 0.09471122175455093, validation loss: 0.16285981237888336\n",
            "AUC 0.9852218175638202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Scores through training')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "Retrain graphsage on full dataset,\n",
        "Choose classifier,\n",
        "Write prediction file"
      ],
      "metadata": {
        "id": "F-nVqxw1rR7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train GraphSage on full dataset"
      ],
      "metadata": {
        "id": "EVurQzgjVntH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- Parameters -------------- #\n",
        "nepochs = 450\n",
        "milestones = np.arange(0, nepochs, 400)\n",
        "lr = 0.01\n",
        "gamma = 0.5\n",
        "hidden_dim = 32\n",
        "\n",
        "\n",
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "model = GraphSAGE(train_pos_g.ndata['feat'].shape[1], hidden_dim).to(device)\n",
        "pred = MLPPredictor(hidden_dim).to(device)\n",
        "# in this case, loss in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=lr)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "\n",
        "validation_scores = []\n",
        "training_scores = []\n",
        "min_loss = np.infty\n",
        "for e in range(nepochs):\n",
        "    # forward\n",
        "    h = model(train_pos_g, train_pos_g.ndata['feat'])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    #weights = torch.cat([2*torch.ones(pos_score.shape[0]), torch.ones(neg_score.shape[0])]).to(device)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "    \n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, training loss: {}'.format(e, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMYTCQ5MVm99",
        "outputId": "33b54110-d551-4d46-d480-602d4ce00909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, training loss: 0.7090413570404053\n",
            "In epoch 5, training loss: 0.68782639503479\n",
            "In epoch 10, training loss: 0.6723989248275757\n",
            "In epoch 15, training loss: 0.6246200799942017\n",
            "In epoch 20, training loss: 0.5637667775154114\n",
            "In epoch 25, training loss: 0.5204281210899353\n",
            "In epoch 30, training loss: 0.4838293194770813\n",
            "In epoch 35, training loss: 0.44801729917526245\n",
            "In epoch 40, training loss: 0.4243641495704651\n",
            "In epoch 45, training loss: 0.40974128246307373\n",
            "In epoch 50, training loss: 0.3805137574672699\n",
            "In epoch 55, training loss: 0.3594801723957062\n",
            "In epoch 60, training loss: 0.3453100919723511\n",
            "In epoch 65, training loss: 0.33180806040763855\n",
            "In epoch 70, training loss: 0.31633180379867554\n",
            "In epoch 75, training loss: 0.2923279106616974\n",
            "In epoch 80, training loss: 0.26378992199897766\n",
            "In epoch 85, training loss: 0.28803834319114685\n",
            "In epoch 90, training loss: 0.2530663311481476\n",
            "In epoch 95, training loss: 0.24017050862312317\n",
            "In epoch 100, training loss: 0.23229211568832397\n",
            "In epoch 105, training loss: 0.2227092832326889\n",
            "In epoch 110, training loss: 0.21565945446491241\n",
            "In epoch 115, training loss: 0.20970971882343292\n",
            "In epoch 120, training loss: 0.2044621706008911\n",
            "In epoch 125, training loss: 0.19950079917907715\n",
            "In epoch 130, training loss: 0.1949869841337204\n",
            "In epoch 135, training loss: 0.19085758924484253\n",
            "In epoch 140, training loss: 0.18736840784549713\n",
            "In epoch 145, training loss: 0.18782098591327667\n",
            "In epoch 150, training loss: 0.18362466990947723\n",
            "In epoch 155, training loss: 0.17759133875370026\n",
            "In epoch 160, training loss: 0.17379294335842133\n",
            "In epoch 165, training loss: 0.17174266278743744\n",
            "In epoch 170, training loss: 0.16866999864578247\n",
            "In epoch 175, training loss: 0.16602307558059692\n",
            "In epoch 180, training loss: 0.16382014751434326\n",
            "In epoch 185, training loss: 0.16227540373802185\n",
            "In epoch 190, training loss: 0.1599511355161667\n",
            "In epoch 195, training loss: 0.15851184725761414\n",
            "In epoch 200, training loss: 0.16455484926700592\n",
            "In epoch 205, training loss: 0.15555690228939056\n",
            "In epoch 210, training loss: 0.15592937171459198\n",
            "In epoch 215, training loss: 0.15254361927509308\n",
            "In epoch 220, training loss: 0.15214917063713074\n",
            "In epoch 225, training loss: 0.15009765326976776\n",
            "In epoch 230, training loss: 0.14855870604515076\n",
            "In epoch 235, training loss: 0.14729219675064087\n",
            "In epoch 240, training loss: 0.14597384631633759\n",
            "In epoch 245, training loss: 0.14600953459739685\n",
            "In epoch 250, training loss: 0.14286497235298157\n",
            "In epoch 255, training loss: 0.14348849654197693\n",
            "In epoch 260, training loss: 0.14166587591171265\n",
            "In epoch 265, training loss: 0.13917692005634308\n",
            "In epoch 270, training loss: 0.13710789382457733\n",
            "In epoch 275, training loss: 0.13652263581752777\n",
            "In epoch 280, training loss: 0.13559280335903168\n",
            "In epoch 285, training loss: 0.13386662304401398\n",
            "In epoch 290, training loss: 0.1339408904314041\n",
            "In epoch 295, training loss: 0.13241735100746155\n",
            "In epoch 300, training loss: 0.13324008882045746\n",
            "In epoch 305, training loss: 0.13149769604206085\n",
            "In epoch 310, training loss: 0.1302240490913391\n",
            "In epoch 315, training loss: 0.13046525418758392\n",
            "In epoch 320, training loss: 0.12903276085853577\n",
            "In epoch 325, training loss: 0.1287355273962021\n",
            "In epoch 330, training loss: 0.12823936343193054\n",
            "In epoch 335, training loss: 0.12821198999881744\n",
            "In epoch 340, training loss: 0.12769514322280884\n",
            "In epoch 345, training loss: 0.12615537643432617\n",
            "In epoch 350, training loss: 0.12688058614730835\n",
            "In epoch 355, training loss: 0.12542100250720978\n",
            "In epoch 360, training loss: 0.12856119871139526\n",
            "In epoch 365, training loss: 0.12769053876399994\n",
            "In epoch 370, training loss: 0.1254972368478775\n",
            "In epoch 375, training loss: 0.1244966983795166\n",
            "In epoch 380, training loss: 0.12317103147506714\n",
            "In epoch 385, training loss: 0.12279189378023148\n",
            "In epoch 390, training loss: 0.1212589219212532\n",
            "In epoch 395, training loss: 0.12118199467658997\n",
            "In epoch 400, training loss: 0.12176581472158432\n",
            "In epoch 405, training loss: 0.12027813494205475\n",
            "In epoch 410, training loss: 0.11829177290201187\n",
            "In epoch 415, training loss: 0.11991412937641144\n",
            "In epoch 420, training loss: 0.11700273305177689\n",
            "In epoch 425, training loss: 0.11704879999160767\n",
            "In epoch 430, training loss: 0.11845112591981888\n",
            "In epoch 435, training loss: 0.11608877778053284\n",
            "In epoch 440, training loss: 0.11460965871810913\n",
            "In epoch 445, training loss: 0.1154828816652298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"embeddingSAGE.npy\", 'wb') as f:\n",
        "    np.save(f, h.cpu().detach().numpy())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-09T22:12:41.655594Z",
          "iopub.execute_input": "2022-02-09T22:12:41.656288Z",
          "iopub.status.idle": "2022-02-09T22:12:41.677008Z",
          "shell.execute_reply.started": "2022-02-09T22:12:41.656249Z",
          "shell.execute_reply": "2022-02-09T22:12:41.676243Z"
        },
        "trusted": true,
        "id": "66RNHRjw_J95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier with NLP"
      ],
      "metadata": {
        "id": "J07QZRT7zUPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write predictions to a file\n",
        "TEST_EDGE_LIST_PATH = PATH+\"citation-prediction-altegrad/test.txt\"\n",
        "G_test = nx.read_edgelist(TEST_EDGE_LIST_PATH, delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
        "G_test.add_nodes_from(G)\n",
        "dgl_test = dgl.from_networkx(G_test).to(device)\n",
        "\n",
        "test_u, test_v = dgl_test.edges()\n",
        "test_g = dgl.graph((test_u, test_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "h = model(g, g.ndata['feat'])\n",
        "y_pred = pred.output(test_g, h)"
      ],
      "metadata": {
        "id": "kPu3wHoBTOy1",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:13:03.736207Z",
          "iopub.execute_input": "2022-02-09T22:13:03.736776Z",
          "iopub.status.idle": "2022-02-09T22:13:11.791774Z",
          "shell.execute_reply.started": "2022-02-09T22:13:03.736736Z",
          "shell.execute_reply": "2022-02-09T22:13:11.790967Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier with XGB boost"
      ],
      "metadata": {
        "id": "mQgmtr-NmNb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "boolSAGE = True\n",
        "\n",
        "if boolSAGE:\n",
        "    with open(PATH+'/train_test_split.npy', 'rb') as f:\n",
        "        \n",
        "        train_pos_u = np.load(f)\n",
        "        train_pos_v = np.load(f)\n",
        "        train_neg_u = np.load(f)\n",
        "        train_neg_v = np.load(f)\n",
        "\n",
        "        test_pos_u = np.load(f)\n",
        "        test_pos_v = np.load(f)\n",
        "        test_neg_u = np.load(f)\n",
        "        test_neg_v = np.load(f)\n",
        "        \n",
        "    test_edge_list_split = [(test_pos_u[i], test_pos_v[i]) for i in range(len(test_pos_u))]\n",
        "    test_neg_edge_list = [(test_neg_u[i], test_neg_v[i]) for i in range(len(test_neg_u))]\n",
        "    del train_pos_u, train_pos_v, train_neg_u, train_neg_v, test_pos_u, test_pos_v, test_neg_u, test_neg_v\n",
        "\n",
        "else:\n",
        "    test_edge_list_split = random.sample(G.edges(), int(0.5 * G.number_of_edges()))\n",
        "    test_edge_list = list(test_edge_list_split)\n",
        "    test_neg_edge_list = random.sample(neg_G.edges(), int(0.5 * neg_G.number_of_edges()))\n",
        "\n",
        "# Remove some edges\n",
        "train_G = G.copy()\n",
        "train_G.remove_edges_from(test_edge_list_split)\n",
        "train_neg_G = neg_G.copy()\n",
        "train_neg_G.remove_edges_from(test_neg_edge_list)\n"
      ],
      "metadata": {
        "id": "2P9asNY1miHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def give_features_from_embedding(emb, edges):\n",
        "    '''\n",
        "    edges can be an iterator\n",
        "    '''\n",
        "    dist = emb[[i for i in map(lambda x: x[0], edges)]] - emb[[i for i in map(lambda x: x[1], edges)]]\n",
        "    l2_dist_neg = np.linalg.norm(dist, ord = 2, axis = 1)\n",
        "    l1_dist_neg = np.linalg.norm(dist, ord = 1, axis = 1)\n",
        "    del dist\n",
        "    \n",
        "    hadamard_neg = np.sum(emb[[i for i in map(lambda x: x[0],  edges)]] * emb[[i for i in map(lambda x: x[1],  edges)]], axis = 1)\n",
        "    \n",
        "    return np.c_[l2_dist_neg, l1_dist_neg, hadamard_neg]\n",
        "\n",
        "\n",
        "# Train dataset \n",
        "h = model(train_pos_g, train_pos_g.ndata['feat'])\n",
        "X_pos = give_features_from_embedding(h, G.edges())\n",
        "X_neg = give_features_from_embedding(h, neg_G.edges())\n",
        "X_train = torch.cat([X_pos, X_neg])\n",
        "y_train = torch.cat([torch.ones(X_pos.shape[0]), torch.zeros(X_neg.shape[0])])\n",
        "\n",
        "c = list(zip(X_train, y_train))\n",
        "random.shuffle(c)\n",
        "X_train, y_train = zip(*c)\n",
        "\n",
        "# Test dataset\n",
        "\n",
        "\n",
        "test_edge_list = [(test_pos_u[i], test_pos_v[i]) for i in range(len(test_pos_u))]\n",
        "test_neg_edge_list = [(test_neg_u[i], test_neg_v[i]) for i in range(len(test_neg_u))]\n",
        "\n",
        "y_test = np.zeros(len(test_edge_list_split) + len(test_neg_edge_list))\n",
        "y_test[:len(test_edge_list_split)] = 1\n",
        "\n",
        "test_nodes = test_edge_list + test_neg_edge_list\n",
        "del test_edge_list_split, test_neg_edge_list\n",
        "\n",
        "X_test = give_features_from_embedding(h.cpu().detach().numpy(), test_nodes)\n",
        "\n",
        "\n",
        "clf = xgb.XGBClassifier(n_estimators = 800, max_depth = 4, subsample = 0.7, colsample_bytree = 0.75,  tree_method = 'gpu_hist',gpu_predictor = 'gpu_predictor')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "evaluate_estimator(clf, X_test, y_test)"
      ],
      "metadata": {
        "id": "FYVt_6oxIQXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Write prediction file"
      ],
      "metadata": {
        "id": "RcubUI-VeifG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_edges = list(G_test.edges())\n",
        "u_test, v_test =  test_g.edges()\n",
        "list_edges = list(zip(u_test.cpu().detach().numpy(), v_test.cpu().detach().numpy()))\n",
        "\n",
        "dict_idx = {}\n",
        "for j,pair in enumerate(list_edges):\n",
        "    dict_idx[pair] = j\n",
        "    \n",
        "file = open(TEST_EDGE_LIST_PATH, \"r\")\n",
        "submission_file = open(PATH+\"submission.csv\",\"w\")\n",
        "csv_out = csv.writer(submission_file)\n",
        "csv_out.writerow(['id','predicted'])\n",
        "\n",
        "count = 0\n",
        "for line in file:\n",
        "    line_edge = line.split(',')\n",
        "    e = (int(line_edge[0]), int(line_edge[1]))\n",
        "    try:\n",
        "        #idx = list_edges.index(e)\n",
        "        row = [count, float(y_pred[dict_idx[e]].detach())]\n",
        "        csv_out.writerow(row)\n",
        "    except:\n",
        "        break\n",
        "    count += 1\n",
        "    \n",
        "file.close()\n",
        "submission_file.close()\n"
      ],
      "metadata": {
        "id": "UcnTt1uP4nbO",
        "execution": {
          "iopub.status.busy": "2022-02-09T22:45:50.419490Z",
          "iopub.execute_input": "2022-02-09T22:45:50.419746Z",
          "iopub.status.idle": "2022-02-09T22:45:53.298655Z",
          "shell.execute_reply.started": "2022-02-09T22:45:50.419718Z",
          "shell.execute_reply": "2022-02-09T22:45:53.297742Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = 0\n",
        "neg = 0\n",
        "for i in y_pred:\n",
        "    if float(i.detach())>0.5:\n",
        "      pos+=1\n",
        "    else :\n",
        "      neg+=1"
      ],
      "metadata": {
        "id": "oMIgmL76hlSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos, neg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsj599EqqFE2",
        "outputId": "94ecf1fa-345a-414c-dc69-3528c92d69d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96861, 116523)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TluhSzXQqGej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}